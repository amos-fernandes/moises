"""
Alpha Vantage Data Loader Otimizado para A√ß√µes Americanas
Foco em alta qualidade de dados para 60% assertividade
"""

import requests
import pandas as pd
import numpy as np
from typing import Dict, Optional, List
import time
import logging
from datetime import datetime, timedelta
import json

logger = logging.getLogger(__name__)

class AlphaVantageLoader:
    """
    Loader otimizado para Alpha Vantage
    Especializado em a√ß√µes americanas para m√°xima assertividade
    """
    
    def __init__(self, api_key: str = "0BZTLZG8FP5KZHFV"):
        self.api_key = api_key
        self.base_url = "https://www.alphavantage.co/query"
        self.rate_limit_delay = 12  # 5 calls per minute = 12s delay
        self.last_call_time = 0
        
        # Cache para evitar chamadas desnecess√°rias
        self.cache = {}
        
    def _respect_rate_limit(self):
        """Respeita o rate limit da API"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_call_time
        
        if time_since_last_call < self.rate_limit_delay:
            sleep_time = self.rate_limit_delay - time_since_last_call
            logger.info(f"‚è∞ Rate limit: aguardando {sleep_time:.1f}s")
            time.sleep(sleep_time)
        
        self.last_call_time = time.time()
    
    def get_intraday_data(self, symbol: str, interval: str = "60min", outputsize: str = "full") -> Optional[pd.DataFrame]:
        """
        Busca dados intraday otimizados para a√ß√µes americanas
        """
        self._respect_rate_limit()
        
        # Verifica cache primeiro
        cache_key = f"{symbol}_{interval}_{outputsize}"
        if cache_key in self.cache:
            cache_time, data = self.cache[cache_key]
            # Cache v√°lido por 1 hora
            if time.time() - cache_time < 3600:
                logger.info(f"üìã Usando cache para {symbol}")
                return data
        
        params = {
            'function': 'TIME_SERIES_INTRADAY',
            'symbol': symbol,
            'interval': interval,
            'apikey': self.api_key,
            'outputsize': outputsize,
            'datatype': 'json'
        }
        
        try:
            logger.info(f"üì° Buscando dados Alpha Vantage: {symbol} ({interval})")
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Verifica erros da API
            if "Error Message" in data:
                logger.error(f"‚ùå Erro da API: {data['Error Message']}")
                return None
            
            if "Note" in data:
                logger.warning(f"‚ö†Ô∏è Limite da API: {data['Note']}")
                time.sleep(60)  # Espera 1 minuto se atingir limite
                return None
            
            # Extrai dados das s√©ries temporais
            time_series_key = f"Time Series ({interval})"
            if time_series_key not in data:
                logger.error(f"‚ùå Chave n√£o encontrada: {time_series_key}")
                logger.error(f"Chaves dispon√≠veis: {list(data.keys())}")
                return None
            
            time_series = data[time_series_key]
            
            # Converte para DataFrame
            df = pd.DataFrame.from_dict(time_series, orient='index')
            df.index = pd.to_datetime(df.index)
            df.sort_index(inplace=True)
            
            # Renomeia colunas
            df.columns = ['open', 'high', 'low', 'close', 'volume']
            
            # Converte tipos
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # Remove dados inv√°lidos
            df = df.dropna()
            
            if df.empty:
                logger.error(f"‚ùå DataFrame vazio para {symbol}")
                return None
            
            # Cache do resultado
            self.cache[cache_key] = (time.time(), df.copy())
            
            logger.info(f"‚úÖ {symbol}: {len(df)} registros carregados")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Erro buscando {symbol}: {e}")
            return None
    
    def get_daily_data(self, symbol: str, outputsize: str = "full") -> Optional[pd.DataFrame]:
        """
        Busca dados di√°rios para an√°lise de longo prazo
        """
        self._respect_rate_limit()
        
        params = {
            'function': 'TIME_SERIES_DAILY',
            'symbol': symbol,
            'apikey': self.api_key,
            'outputsize': outputsize,
            'datatype': 'json'
        }
        
        try:
            logger.info(f"üì° Buscando dados di√°rios: {symbol}")
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            if "Error Message" in data:
                logger.error(f"‚ùå Erro da API: {data['Error Message']}")
                return None
            
            time_series = data.get("Time Series (Daily)", {})
            if not time_series:
                logger.error(f"‚ùå Dados di√°rios n√£o encontrados para {symbol}")
                return None
            
            df = pd.DataFrame.from_dict(time_series, orient='index')
            df.index = pd.to_datetime(df.index)
            df.sort_index(inplace=True)
            
            df.columns = ['open', 'high', 'low', 'close', 'volume']
            
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df = df.dropna()
            
            logger.info(f"‚úÖ {symbol} di√°rio: {len(df)} registros")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Erro buscando dados di√°rios {symbol}: {e}")
            return None
    
    def get_company_overview(self, symbol: str) -> Optional[Dict]:
        """
        Busca informa√ß√µes fundamentais da empresa
        """
        self._respect_rate_limit()
        
        params = {
            'function': 'OVERVIEW',
            'symbol': symbol,
            'apikey': self.api_key
        }
        
        try:
            logger.info(f"üìä Buscando overview: {symbol}")
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            if not data or "Symbol" not in data:
                logger.warning(f"‚ö†Ô∏è Overview n√£o encontrado para {symbol}")
                return None
            
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erro buscando overview {symbol}: {e}")
            return None
    
    def get_technical_indicators(self, symbol: str, indicator: str, interval: str = "60min", **kwargs) -> Optional[pd.DataFrame]:
        """
        Busca indicadores t√©cnicos prontos da Alpha Vantage
        """
        self._respect_rate_limit()
        
        params = {
            'function': indicator,
            'symbol': symbol,
            'interval': interval,
            'apikey': self.api_key,
            **kwargs
        }
        
        try:
            logger.info(f"üìà Buscando {indicator}: {symbol}")
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Encontra a chave dos dados t√©cnicos
            tech_key = None
            for key in data.keys():
                if "Technical Analysis" in key or indicator.upper() in key:
                    tech_key = key
                    break
            
            if not tech_key:
                logger.error(f"‚ùå Dados t√©cnicos n√£o encontrados para {indicator}")
                return None
            
            tech_data = data[tech_key]
            
            df = pd.DataFrame.from_dict(tech_data, orient='index')
            df.index = pd.to_datetime(df.index)
            df.sort_index(inplace=True)
            
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Erro buscando indicador {indicator}: {e}")
            return None

class USMarketDataManager:
    """
    Gerenciador de dados espec√≠fico para mercado americano
    Otimizado para alta assertividade (60%+)
    """
    
    def __init__(self, api_key: str = "0BZTLZG8FP5KZHFV"):
        self.loader = AlphaVantageLoader(api_key)
        self.us_symbols = ["AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "TSLA"]
        self.data_cache = {}
        
    def load_us_market_data(self, symbols: Optional[List[str]] = None, interval: str = "60min") -> Dict[str, pd.DataFrame]:
        """
        Carrega dados de m√∫ltiplas a√ß√µes americanas
        """
        if symbols is None:
            symbols = self.us_symbols
        
        market_data = {}
        
        logger.info(f"üá∫üá∏ Carregando dados do mercado americano: {len(symbols)} a√ß√µes")
        
        for symbol in symbols:
            try:
                df = self.loader.get_intraday_data(symbol, interval)
                if df is not None and len(df) > 50:  # M√≠nimo 50 registros
                    market_data[symbol] = df
                    logger.info(f"‚úÖ {symbol}: {len(df)} registros ({df.index[0]} a {df.index[-1]})")
                else:
                    logger.warning(f"‚ö†Ô∏è {symbol}: Dados insuficientes ou inv√°lidos")
                    
            except Exception as e:
                logger.error(f"‚ùå Erro carregando {symbol}: {e}")
        
        logger.info(f"üìä Total carregado: {len(market_data)}/{len(symbols)} a√ß√µes")
        return market_data
    
    def enrich_with_fundamentals(self, symbols: List[str]) -> Dict[str, Dict]:
        """
        Enriquece dados com informa√ß√µes fundamentais
        """
        fundamentals = {}
        
        for symbol in symbols:
            try:
                overview = self.loader.get_company_overview(symbol)
                if overview:
                    # Extrai m√©tricas importantes
                    fundamentals[symbol] = {
                        'market_cap': overview.get('MarketCapitalization', 0),
                        'pe_ratio': overview.get('PERatio', 0),
                        'peg_ratio': overview.get('PEGRatio', 0),
                        'dividend_yield': overview.get('DividendYield', 0),
                        'profit_margin': overview.get('ProfitMargin', 0),
                        'sector': overview.get('Sector', 'Unknown'),
                        'industry': overview.get('Industry', 'Unknown'),
                        '52_week_high': overview.get('52WeekHigh', 0),
                        '52_week_low': overview.get('52WeekLow', 0),
                    }
                    
                    # Converte strings para n√∫meros
                    for key, value in fundamentals[symbol].items():
                        if key not in ['sector', 'industry']:
                            try:
                                fundamentals[symbol][key] = float(value) if value != 'None' else 0
                            except:
                                fundamentals[symbol][key] = 0
                                
            except Exception as e:
                logger.error(f"‚ùå Erro carregando fundamentais {symbol}: {e}")
        
        return fundamentals
    
    def get_market_snapshot(self) -> Dict:
        """
        Retorna snapshot do mercado americano
        """
        # Carrega dados das principais a√ß√µes
        market_data = self.load_us_market_data(self.us_symbols[:3], "60min")  # Top 3 para velocidade
        
        if not market_data:
            return {"status": "error", "message": "Sem dados dispon√≠veis"}
        
        snapshot = {
            "timestamp": datetime.now(),
            "symbols_loaded": list(market_data.keys()),
            "market_summary": {}
        }
        
        # Calcula resumo do mercado
        total_symbols = len(market_data)
        up_count = 0
        down_count = 0
        
        for symbol, df in market_data.items():
            if len(df) >= 2:
                latest = df.iloc[-1]
                previous = df.iloc[-2]
                change = (latest['close'] - previous['close']) / previous['close']
                
                if change > 0:
                    up_count += 1
                else:
                    down_count += 1
                
                snapshot["market_summary"][symbol] = {
                    "price": latest['close'],
                    "change_pct": change * 100,
                    "volume": latest['volume']
                }
        
        snapshot["market_sentiment"] = {
            "up_stocks": up_count,
            "down_stocks": down_count,
            "net_sentiment": (up_count - down_count) / total_symbols if total_symbols > 0 else 0
        }
        
        return snapshot

# Exemplo de uso
if __name__ == "__main__":
    print("üì° Alpha Vantage Data Loader para Mercado Americano")
    
    # Teste b√°sico
    loader = AlphaVantageLoader()
    data_manager = USMarketDataManager()
    
    # Carrega dados de uma a√ß√£o
    aapl_data = loader.get_intraday_data("AAPL", "60min")
    if aapl_data is not None:
        print(f"‚úÖ AAPL: {len(aapl_data)} registros carregados")
        print(f"üìà √öltimo pre√ßo: ${aapl_data['close'].iloc[-1]:.2f}")
    
    # Snapshot do mercado
    snapshot = data_manager.get_market_snapshot()
    print(f"üìä Snapshot: {snapshot['symbols_loaded']}")
    print(f"üìà Sentimento: {snapshot['market_sentiment']}")